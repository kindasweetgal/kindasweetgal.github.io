<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>吴恩达机器学习 课时 1 学习笔记</title>
    <url>/2020/06/06/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20%E8%AF%BE%E6%97%B6%201%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<a id="more"></a>

<h1 id="吴恩达机器学习-课时-1-学习笔记"><a href="#吴恩达机器学习-课时-1-学习笔记" class="headerlink" title="吴恩达机器学习 课时 1 学习笔记"></a>吴恩达机器学习 课时 1 学习笔记</h1><h2 id="课时1-1-欢迎参加《机器学习》课程"><a href="#课时1-1-欢迎参加《机器学习》课程" class="headerlink" title="课时1-1 欢迎参加《机器学习》课程"></a>课时1-1 欢迎参加《机器学习》课程</h2><h5 id="机器学习："><a href="#机器学习：" class="headerlink" title="机器学习："></a>机器学习：</h5><p>​    1.人工智能发展出来的一个领域</p>
<p>​    2.计算机开发的一项新功能</p>
<h5 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h5><p>​    1.数据挖掘</p>
<p>​        自动化、互联网上的大量数据</p>
<p>​    2.不能用手来编程的应用</p>
<p>​        手写识别，自然语言处理和计算机视觉</p>
<p>​    3.私人定制程序</p>
<p>​        产品推荐</p>
<p>​    4.理解人类学习（大脑、真实的AI）</p>
<h2 id="课时1-2-什么是机器学习"><a href="#课时1-2-什么是机器学习" class="headerlink" title="课时1-2 什么是机器学习"></a>课时1-2 什么是机器学习</h2><h5 id="机器学习的定义："><a href="#机器学习的定义：" class="headerlink" title="机器学习的定义："></a>机器学习的定义：</h5><p>Arthur Samuel：Field of study that gives computers the ability to learn without being explicitly programmed.</p>
<p>在没有明确设置的情况下，使计算机具有学习能力的研究领域</p>
<p>Tom Mitchell ：Well-posed Learning Problem: A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measure by P, improves with experience E.</p>
<p>计算机程序从经验E中进行学习，解决某一任务T，进行某一性能度量P，通过P测定在T上的表现因经验E提高。</p>
<h5 id="机器学习算法："><a href="#机器学习算法：" class="headerlink" title="机器学习算法："></a>机器学习算法：</h5><pre><code>监督学习</code></pre><p>​    无监督学习</p>
<p>其他： 强化学习，推荐系统</p>
<h2 id="课时1-3-监督学习"><a href="#课时1-3-监督学习" class="headerlink" title="课时1-3 监督学习"></a>课时1-3 监督学习</h2><p>例子：房价预测，肿瘤良性or恶性预测</p>
<p><strong>监督学习</strong>：给一个数据集其中包括了<strong>正确答案</strong>，</p>
<p><strong>1. 回归问题</strong>：预测更多连续的有价值的输出</p>
<p><strong>2. 分类</strong>：预测一个（组）离散值输出</p>
<h2 id="课时1-4-无监督学习"><a href="#课时1-4-无监督学习" class="headerlink" title="课时1-4 无监督学习"></a>课时1-4 无监督学习</h2><p>Unsupervised algorithm</p>
<p>聚类算法：组织计算机集群，社交网络分析，市场细分，天文数据分析</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>吴恩达机器学习 课时2 学习笔记</title>
    <url>/2020/06/06/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20%E8%AF%BE%E6%97%B62%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<a id="more"></a>

<h1 id="吴恩达机器学习-课时2"><a href="#吴恩达机器学习-课时2" class="headerlink" title="吴恩达机器学习 课时2"></a>吴恩达机器学习 课时2</h1><h3 id="课时2-1-模型描述"><a href="#课时2-1-模型描述" class="headerlink" title="课时2-1 模型描述"></a>课时2-1 模型描述</h3><p>m=训练样本数量</p>
<p>x=输入变量/特征</p>
<p>y=输出变量/目标变量</p>
<p>（x，y）一个训练样本</p>
<p>（x<sup>(i)</sup>,y<sup>(i)</sup>） 第i个样本·</p>
<p>h假设函数（hypothesis ）</p>
<h3 id="课时2-2-代价函数"><a href="#课时2-2-代价函数" class="headerlink" title="课时2-2 代价函数"></a>课时2-2 代价函数</h3><p>h<sub>θ</sub>（x)=θ<sub>0</sub>+θ<sub>1</sub>*x</p>
<p>尽量选择参数合理准确地预测y</p>
<p>代价函数：（平方误差代价函数）<br>$$<br>minimize \frac{1}{2m}\sum_{i=1}^m(h_θ(x^{(i)})-y^{(i)})^2<br>$$<br>（加二分之一为了好求导）</p>
<h3 id="课时2-3-代价函数（一）"><a href="#课时2-3-代价函数（一）" class="headerlink" title="课时2-3 代价函数（一）"></a>课时2-3 代价函数（一）</h3><p>![](F:\blog\blog\source_posts\pictures\cost function.png)</p>
<h3 id="课时2-4-代价函数（二）"><a href="#课时2-4-代价函数（二）" class="headerlink" title="课时2-4 代价函数（二）"></a>课时2-4 代价函数（二）</h3><p>代价函数计算，等高线绘制</p>
<h3 id="课时2-5-梯度下降"><a href="#课时2-5-梯度下降" class="headerlink" title="课时2-5 梯度下降"></a>课时2-5 梯度下降</h3><p><img src="F:%5Cblog%5Cblog%5Csource_posts%5Cpictures%5Cgradient_descent.jpg" alt=""></p>
<h3 id="课时2-6-梯度下降知识点总结"><a href="#课时2-6-梯度下降知识点总结" class="headerlink" title="课时2-6 梯度下降知识点总结"></a>课时2-6 梯度下降知识点总结</h3><p>学习率：太小下降太慢，太大来回跳跃。</p>
<p>局部极小值：梯度下降会自动采用更小的步幅</p>
<h3 id="课时2-7-线性回归的梯度下降"><a href="#课时2-7-线性回归的梯度下降" class="headerlink" title="课时2-7 线性回归的梯度下降"></a>课时2-7 线性回归的梯度下降</h3><p><img src="F:%5Cblog%5Cblog%5Csource_posts%5Cpictures%5C2-7.png" alt=""></p>
<p>线性回归模型呈碗状</p>
<p>Batch梯度下降法：全览整个数据集</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
</search>
